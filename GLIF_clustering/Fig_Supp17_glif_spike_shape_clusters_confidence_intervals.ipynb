{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to cluster cells by GLIF and spike shape parameters using iterative binary clustering and generate confidence intervals for clustering similarity\n",
    "### Teeter et al. 2018\n",
    "#### This notebook runs the iterative binary approach to generate clusters from the GLIF and spike-shape parameters. This code outputs graphs showing the confidence intervals on clustering similarity, the latter measured using the Adjusted Rand Index and the Adjusted Variation of Information. This corresponds to Supplemental Figure 17 in the paper. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: plotrix\n",
      "Warning message:\n",
      "In library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE, : there is no package called 'plotrix'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  There is a binary version available (and will be installed) but the\n",
      "  source version is later:\n",
      "        binary source\n",
      "plotrix  3.6-1    3.7\n",
      "\n",
      "package 'plotrix' successfully unpacked and MD5 sums checked\n",
      "\n",
      "The downloaded binary packages are in\n",
      "\tC:\\Users\\menonv\\AppData\\Local\\Temp\\RtmpsBeaGa\\downloaded_packages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: plotrix\n",
      "\n",
      "Attaching package: 'plotrix'\n",
      "\n",
      "The following object is masked from 'package:gplots':\n",
      "\n",
      "    plotCI\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if (!require(ape)) {install.packages(\"ape\", repos = \"http://cran.us.r-project.org\")}\n",
    "if (!require(e1071)) {install.packages(\"e1071\", repos = \"http://cran.us.r-project.org\")}\n",
    "if (!require(gplots)) {install.packages(\"gplots\", repos = \"http://cran.us.r-project.org\")}\n",
    "if (!require(plotrix)) {install.packages(\"plotrix\", repos = \"http://cran.us.r-project.org\")}\n",
    "require(ape)\n",
    "require(e1071)\n",
    "require(gplots)\n",
    "require(mclust)\n",
    "require(plotrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Load data and metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###model parameters\n",
    "dat=read.table(\"GLIF_param_plus_spike_features_7_27_17.csv\",sep=\"\\t\",as.is=T,row.names=1,check.names=F,header=T)\n",
    "metadata=dat[,1:2]\n",
    "fulldat=dat[,-c(1:2)]\n",
    "\n",
    "###Cre line metadata\n",
    "crecols=read.csv(\"cre_colors.csv\",as.is=T,header=F)\n",
    "newcols=rgb(crecols[,2:4],maxColorValue = 255)\n",
    "names(newcols)=crecols[,5]\n",
    "colvec=newcols[match(metadata$cre,crecols[,1])]\n",
    "cre_order=c(\"Htr3a\",\"Ndnf\",\"Vip\",\"Sst\",\"Pvalb\",\"Nkx2-1\",\"Chat\",\"Chrna2\",\"Cux2\",\"Nr5a1\",\"Scnn1a-Tg2\",\"Scnn1a-Tg3\",\"Rorb\",\"Rbp4\",\"Ntsr1\",\"Ctgf\")\n",
    "  \n",
    "###features\n",
    "featdat=read.table(\"features_7_27_17.csv\",as.is=T,row.names=1,check.names=F,sep=\",\",header=T)\n",
    "featmetadata=featdat[,1:2]\n",
    "featfulldat=featdat[,c(\"tau\",\"ri\",\"vrest\",\"threshold_i_long_square\",\"threshold_v_long_square\",\"peak_v_long_square\",\"fast_trough_v_long_square\",\"trough_v_long_square\",\"upstroke_downstroke_ratio_long_square\",\"upstroke_downstroke_ratio_short_square\",\"sag\",\"f_i_curve_slope\",\"latency\",\"max_burstiness_across_sweeps\")]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Apply log transform to skewed parameters/features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###model parameters\n",
    "for (ii in 1:ncol(fulldat)) {\n",
    "  if (min(fulldat[,ii])*max(fulldat[,ii])>0) {\n",
    "    if (min(fulldat[,ii])>0) {\n",
    "      if (skewness(fulldat[,ii])>skewness(log10(fulldat[,ii]))) {\n",
    "        fulldat[,ii]=log10(fulldat[,ii])\n",
    "      }\n",
    "    } else {\n",
    "      if (skewness(-fulldat[,ii])>skewness(log10(-fulldat[,ii]))) {\n",
    "        fulldat[,ii]=log10(-fulldat[,ii])\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "fulldat_all=fulldat\n",
    "\n",
    "###features\n",
    "for (ii in 1:ncol(featfulldat)) {\n",
    "  if (min(featfulldat[,ii])*max(featfulldat[,ii])>0) {\n",
    "    if (min(featfulldat[,ii])>0) {\n",
    "      if (skewness(featfulldat[,ii])>skewness(log10(featfulldat[,ii]))) {\n",
    "        featfulldat[,ii]=log10(featfulldat[,ii])\n",
    "      }\n",
    "    } else {\n",
    "      if (skewness(-featfulldat[,ii])>skewness(log10(-featfulldat[,ii]))) {\n",
    "        featfulldat[,ii]=log10(-featfulldat[,ii])\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "featfulldat_all=featfulldat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Load clustering and clustering overlap functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###function to separate data into two clusters and check for cluster separation using SVM-based prediction\n",
    "cluster_into_two=function(fulldat,startseed,meth='ward.D') {\n",
    "  fulldat=scale(fulldat[,apply(fulldat,2,var)>0])\n",
    "  hc=hclust(as.dist(1-cor(t(fulldat),method=\"pearson\")),method=meth)\n",
    "  clustids=cutree(hc,2)\n",
    "  outlist=list()\n",
    "  ###assess predictability using SVM prediction###\n",
    "   fraction_incorrect=c()\n",
    "   inds1=which(clustids==1)\n",
    "   inds2=which(clustids==2)\n",
    "   if (length(inds1)>5 & length(inds2)>5) {\n",
    "     sampfrac1=round(0.5*length(inds1))\n",
    "     sampfrac2=round(0.5*length(inds2))\n",
    "     for (tt in 1:100) {\n",
    "       set.seed(tt+startseed)\n",
    "       sampvec=c(sample(inds1,sampfrac1),sample(inds2,sampfrac2))\n",
    "       setcols=which(apply(fulldat[sampvec,],2,var)>0)\n",
    "       svmpred=predict(svm(x=fulldat[sampvec,setcols],y=clustids[sampvec],type=\"C-classification\"),fulldat[-sampvec,setcols])\n",
    "       conf=table(svmpred,clustids[-sampvec])\n",
    "       fraction_incorrect=c(fraction_incorrect,(conf[2,1]+conf[1,2])/sum(conf))\n",
    "     }\n",
    "   } else {\n",
    "     fraction_incorrect=c(1,1)\n",
    "     fraction_incorrect_rand=c(1,1)\n",
    "   }\n",
    "   outlist[['fraction_incorrect']]=fraction_incorrect\n",
    "   outlist[['clustids']]=clustids\n",
    "  return(outlist)\n",
    "}\n",
    "\n",
    "###function to cluster iteratively using binary splits\n",
    "recursive_clustering=function(keepcols,fulldat_all,fraclim=0.2,splitlim=50,startseed,outlist,methall=\"ward.D\") {\n",
    "  clustmat=fulldat_all[,keepcols]\n",
    "  tempout=cluster_into_two(clustmat,meth=methall,startseed)\n",
    "  if (!is.na(tempout$fraction_incorrect[1])) {\n",
    "    if (max(tempout$fraction_incorrect,na.rm=T)<=fraclim) {\n",
    "      outlist$clustnames[names(tempout$clustids)]=paste(outlist$clustnames[names(tempout$clustids)],tempout$clustids,sep=\"_\")\n",
    "      outlist$fracmat=rbind(outlist$fracmat,tempout$fraction_incorrect)\n",
    "      for (ii in 1:2) {\n",
    "        if (length(which(tempout$clustids==ii))>=10) {\n",
    "        outlist=recursive_clustering(keepcols,fulldat_all[names(tempout$clustids)[tempout$clustids==ii],],fraclim=fraclim,splitlim=splitlim,startseed+ii,outlist)\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "  return(outlist)\n",
    "}\n",
    "\n",
    "###function to calculate Variation of Information or Adjusted Rand Index\n",
    "calc_cluster_diff=function(xvec,yvec,functype=1,credistmat=c(),clustdistmat=c()) {\n",
    "  if (functype==1) {\n",
    "    totaltab=table(xvec,yvec)\n",
    "    rowmat=sweep(totaltab,1,rowSums(totaltab),\"/\")  \n",
    "    colmat=sweep(totaltab,2,colSums(totaltab),\"/\")\n",
    "    summat=(totaltab*(log(rowmat)+log(colmat)))\n",
    "    sumval=sum(summat[totaltab>0])/length(xvec)\n",
    "    return(-sumval) \n",
    "  } else {\n",
    "    return(adjustedRandIndex(xvec,yvec))\n",
    "  }\n",
    "}\n",
    "\n",
    "###function to calculate score based on 100 random permutations\n",
    "rand_cluster_diff=function(xvec,yvec,functype=1,credistmat=c(),clustdistmat=c()) {\n",
    "  allvals=rep(0,100)\n",
    "  for (ii in 1:100) {\n",
    "    set.seed(ii)\n",
    "    allvals[ii]=calc_cluster_diff(xvec,sample(yvec),functype,credistmat,clustdistmat)\n",
    "  }\n",
    "  return(allvals)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Run clustering on GLIF parameters, GLIF parameters+spike shape features, and electrophysiological features using full data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"clustering Features model, using the following parameters: tau,ri,vrest,threshold_i_long_square,threshold_v_long_square,peak_v_long_square,fast_trough_v_long_square,trough_v_long_square,upstroke_downstroke_ratio_long_square,upstroke_downstroke_ratio_short_square,sag,f_i_curve_slope,latency,max_burstiness_across_sweeps\"\n",
      "[1] \"clustering Featuresnospike model, using the following parameters: tau,ri,vrest,threshold_i_long_square,threshold_v_long_square,trough_v_long_square,sag,f_i_curve_slope,latency,max_burstiness_across_sweeps\"\n",
      "[1] \"clustering GLIF1 model, using the following parameters: R_input,C,El,th_inf,spike_cut_length\"\n",
      "[1] \"clustering GLIF2 model, using the following parameters: R_input,C,El,th_inf,spike_cut_length,reset_slope,reset_intercept\"\n",
      "[1] \"clustering GLIF3 model, using the following parameters: R_ASC,C,El,th_inf,total charge 1/300+1/100,total charge 1/3+1/10+1/100,spike_cut_length\"\n",
      "[1] \"clustering GLIF4 model, using the following parameters: R_ASC,C,El,th_inf,total charge 1/300+1/100,total charge 1/3+1/10+1/100,spike_cut_length,reset_slope,reset_intercept\"\n",
      "[1] \"clustering GLIF1_spike_shape model, using the following parameters: R_input,C,El,th_inf,spike_cut_length,peak_v_long_square,fast_trough_v_long_square,upstroke_downstroke_ratio_long_square,upstroke_downstroke_ratio_short_square\"\n",
      "[1] \"clustering GLIF2_spike_shape model, using the following parameters: R_input,C,El,th_inf,spike_cut_length,reset_slope,reset_intercept,peak_v_long_square,fast_trough_v_long_square,upstroke_downstroke_ratio_long_square,upstroke_downstroke_ratio_short_square\"\n",
      "[1] \"clustering GLIF3_spike_shape model, using the following parameters: R_ASC,C,El,th_inf,total charge 1/300+1/100,total charge 1/3+1/10+1/100,spike_cut_length,peak_v_long_square,fast_trough_v_long_square,upstroke_downstroke_ratio_long_square,upstroke_downstroke_ratio_short_square\"\n",
      "[1] \"clustering GLIF4_spike_shape model, using the following parameters: R_ASC,C,El,th_inf,total charge 1/300+1/100,total charge 1/3+1/10+1/100,spike_cut_length,reset_slope,reset_intercept,peak_v_long_square,fast_trough_v_long_square,upstroke_downstroke_ratio_long_square,upstroke_downstroke_ratio_short_square\"\n"
     ]
    }
   ],
   "source": [
    "###specify prefix for output file names###\n",
    "pref=\"iterative_binary_clustering_2018\"\n",
    "parametersets=c(\"Features\",\"Featuresnospike\",\"GLIF1\",\"GLIF2\",\"GLIF3\",\"GLIF4\",\"GLIF1_spike_shape\",\"GLIF2_spike_shape\",\"GLIF3_spike_shape\",\"GLIF4_spike_shape\")\n",
    "fraclimval=0.2  ###maximum fraction of incorrectly classified cells in test set (see recursive_clustering function in cell 3)\n",
    "methall='ward.D'\n",
    "for (nameval in parametersets) {\n",
    "  if (nameval==\"GLIF1\") {keepcols=c(1,3,4,5,8)}\n",
    "  if (nameval==\"GLIF2\") {keepcols=c(1,3,4,5,8,9,10)}\n",
    "  if (nameval==\"GLIF3\") {keepcols=c(2,3,4,5,6,7,8)}\n",
    "  if (nameval==\"GLIF4\") {keepcols=c(2,3,4,5,6,7,8,9,10)}\n",
    "  if (nameval==\"GLIF1_spike_shape\") {keepcols=c(1,3,4,5,8,13:16)}\n",
    "  if (nameval==\"GLIF2_spike_shape\") {keepcols=c(1,3,4,5,8,9,10,13:16)}\n",
    "  if (nameval==\"GLIF3_spike_shape\") {keepcols=c(2,3,4,5,6,7,8,13:16)}\n",
    "  if (nameval==\"GLIF4_spike_shape\") {keepcols=c(2,3,4,5,6,7,8,9,10,13:16)}\n",
    "  if (nameval==\"Features\") {keepcols=1:ncol(featfulldat_all)}\n",
    "  if (nameval==\"Featuresnospike\") {keepcols=c(1,2,3,4,5,8,11,12,13,14)}\n",
    "  \n",
    "  if (nameval %in% c(\"Features\",\"Featuresnospike\")) {\n",
    "    startmat=featfulldat_all\n",
    "  } else {\n",
    "    startmat=fulldat_all\n",
    "  }\n",
    "\n",
    "  print(paste0(\"clustering \",nameval,\" model, using the following parameters: \",paste(colnames(startmat)[keepcols],collapse=\",\")))\n",
    "  startnames=rep(\"1\",nrow(startmat))\n",
    "  names(startnames)=rownames(startmat)\n",
    "  outlist=list()\n",
    "  outlist$clustnames=startnames\n",
    "  outlist$fracmat=c()\n",
    "  allclusts=recursive_clustering(keepcols,startmat,fraclim=fraclimval,splitlim=splitlimval,startseed=1,outlist=outlist)\n",
    "  temptab=table(allclusts$clustnames[intersect(names(allclusts$clustnames),rownames(metadata))],metadata$cre[match(intersect(names(allclusts$clustnames),rownames(metadata)),rownames(metadata))])\n",
    "  colnames(temptab)=sapply(strsplit(colnames(temptab),\"-\"), `[`, 1)\n",
    "  temptab=cbind(temptab,paste(\"Cluster \",rev(1:nrow(temptab)),sep=''))\n",
    "  write.csv(temptab,file=paste0(\"composition_\",pref,\"_\",nameval,\".csv\"))\n",
    "  temptab=allclusts$clustnames\n",
    "  write.csv(temptab,file=paste0(\"cluster_ids_\",pref,\"_\",nameval,\".csv\"))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) Run clustering on GLIF parameters, GLIF parameters+spike shape features, and electrophysiological features using bootstrapped subsets comprising 80% of the cells\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"clustering Features model, using the following parameters: tau,ri,vrest,threshold_i_long_square,threshold_v_long_square,peak_v_long_square,fast_trough_v_long_square,trough_v_long_square,upstroke_downstroke_ratio_long_square,upstroke_downstroke_ratio_short_square,sag,f_i_curve_slope,latency,max_burstiness_across_sweeps\"\n",
      "[1] \"clustering Featuresnospike model, using the following parameters: tau,ri,vrest,threshold_i_long_square,threshold_v_long_square,trough_v_long_square,sag,f_i_curve_slope,latency,max_burstiness_across_sweeps\"\n",
      "[1] \"clustering GLIF1 model, using the following parameters: R_input,C,El,th_inf,spike_cut_length\"\n",
      "[1] \"clustering GLIF2 model, using the following parameters: R_input,C,El,th_inf,spike_cut_length,reset_slope,reset_intercept\"\n",
      "[1] \"clustering GLIF3 model, using the following parameters: R_ASC,C,El,th_inf,total charge 1/300+1/100,total charge 1/3+1/10+1/100,spike_cut_length\"\n",
      "[1] \"clustering GLIF4 model, using the following parameters: R_ASC,C,El,th_inf,total charge 1/300+1/100,total charge 1/3+1/10+1/100,spike_cut_length,reset_slope,reset_intercept\"\n",
      "[1] \"clustering GLIF1_spike_shape model, using the following parameters: R_input,C,El,th_inf,spike_cut_length,peak_v_long_square,fast_trough_v_long_square,upstroke_downstroke_ratio_long_square,upstroke_downstroke_ratio_short_square\"\n",
      "[1] \"clustering GLIF2_spike_shape model, using the following parameters: R_input,C,El,th_inf,spike_cut_length,reset_slope,reset_intercept,peak_v_long_square,fast_trough_v_long_square,upstroke_downstroke_ratio_long_square,upstroke_downstroke_ratio_short_square\"\n",
      "[1] \"clustering GLIF3_spike_shape model, using the following parameters: R_ASC,C,El,th_inf,total charge 1/300+1/100,total charge 1/3+1/10+1/100,spike_cut_length,peak_v_long_square,fast_trough_v_long_square,upstroke_downstroke_ratio_long_square,upstroke_downstroke_ratio_short_square\"\n",
      "[1] \"clustering GLIF4_spike_shape model, using the following parameters: R_ASC,C,El,th_inf,total charge 1/300+1/100,total charge 1/3+1/10+1/100,spike_cut_length,reset_slope,reset_intercept,peak_v_long_square,fast_trough_v_long_square,upstroke_downstroke_ratio_long_square,upstroke_downstroke_ratio_short_square\"\n"
     ]
    }
   ],
   "source": [
    "###specify prefix for output file names###\n",
    "pref=\"iterative_binary_clustering_2018\"\n",
    "parametersets=c(\"Features\",\"Featuresnospike\",\"GLIF1\",\"GLIF2\",\"GLIF3\",\"GLIF4\",\"GLIF1_spike_shape\",\"GLIF2_spike_shape\",\"GLIF3_spike_shape\",\"GLIF4_spike_shape\")\n",
    "fraclimval=0.2  ###maximum fraction of incorrectly classified cells in test set (see recursive_clustering function in cell 3)\n",
    "methall='ward.D'\n",
    "sublist=list()\n",
    "for (nameval in parametersets) {\n",
    "  if (nameval==\"GLIF1\") {keepcols=c(1,3,4,5,8)}\n",
    "  if (nameval==\"GLIF2\") {keepcols=c(1,3,4,5,8,9,10)}\n",
    "  if (nameval==\"GLIF3\") {keepcols=c(2,3,4,5,6,7,8)}\n",
    "  if (nameval==\"GLIF4\") {keepcols=c(2,3,4,5,6,7,8,9,10)}\n",
    "  if (nameval==\"GLIF1_spike_shape\") {keepcols=c(1,3,4,5,8,13:16)}\n",
    "  if (nameval==\"GLIF2_spike_shape\") {keepcols=c(1,3,4,5,8,9,10,13:16)}\n",
    "  if (nameval==\"GLIF3_spike_shape\") {keepcols=c(2,3,4,5,6,7,8,13:16)}\n",
    "  if (nameval==\"GLIF4_spike_shape\") {keepcols=c(2,3,4,5,6,7,8,9,10,13:16)}\n",
    "  if (nameval==\"Features\") {keepcols=1:ncol(featfulldat_all)}\n",
    "  if (nameval==\"Featuresnospike\") {keepcols=c(1,2,3,4,5,8,11,12,13,14)}\n",
    "  \n",
    "  if (nameval %in% c(\"Features\",\"Featuresnospike\")) {\n",
    "    startmat=featfulldat_all\n",
    "  } else {\n",
    "    startmat=fulldat_all\n",
    "  }\n",
    "\n",
    "  print(paste0(\"clustering \",nameval,\" model, using the following parameters: \",paste(colnames(startmat)[keepcols],collapse=\",\")))\n",
    "  startnames=rep(\"1\",nrow(startmat))\n",
    "  names(startnames)=rownames(startmat)\n",
    "  sublist[[nameval]]=list()\n",
    "  cellnum=round(nrow(startmat)*0.8)\n",
    "  for (ii in 1:100) {\n",
    "    set.seed(ii)\n",
    "    startmatrows=sample(1:nrow(startmat),cellnum)\n",
    "    outlist=list()\n",
    "    outlist$clustnames=startnames\n",
    "    outlist$fracmat=c()\n",
    "    allclusts=recursive_clustering(keepcols,startmat[startmatrows,],fraclim=fraclimval,splitlim=splitlimval,startseed=1,outlist=outlist)\n",
    "    sublist[[nameval]][[ii]]=allclusts$clustnames\n",
    "  }\n",
    "  save(sublist,file=paste0(\"bootstrappedclusters_\",pref,\".rda\"))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 7) Calculate Adjusted Rand and Adjusted Variation of Information Index confidence intervals between all clusterings and Cre line segregation, with confidence intervals based on bootstrapping\n",
    "#### This generates the left panel of Supplemental Figure 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>pdf:</strong> 2"
      ],
      "text/latex": [
       "\\textbf{pdf:} 2"
      ],
      "text/markdown": [
       "**pdf:** 2"
      ],
      "text/plain": [
       "pdf \n",
       "  2 "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pref=\"iterative_binary_clustering_2018\"\n",
    "cre_sub_voi=list()\n",
    "cre_sub_ari=list()\n",
    "load(paste0(\"bootstrappedclusters_\",pref,\".rda\"))\n",
    "featclust=featmetadata\n",
    "for (nameval in names(sublist)) {\n",
    "  cre_sub_voi[[nameval]]=c()\n",
    "  cre_sub_ari[[nameval]]=c()\n",
    "  for (ii in 1:length(sublist[[nameval]])) {\n",
    "    checkclust=sublist[[nameval]][[ii]]\n",
    "    checkclust=checkclust[checkclust!=1]\n",
    "    keepclust=featclust[names(checkclust),1]\n",
    "    set.seed(ii)\n",
    "    rand_voi=rand_cluster_diff(keepclust,checkclust,1)\n",
    "    rand_ari=rand_cluster_diff(keepclust,checkclust,2)\n",
    "    cre_sub_voi[[nameval]]=c(cre_sub_voi[[nameval]],mean(rand_voi)-calc_cluster_diff(keepclust,checkclust,1))\n",
    "    cre_sub_ari[[nameval]]=c(cre_sub_ari[[nameval]],calc_cluster_diff(keepclust,checkclust,2)-mean(rand_ari))\n",
    "  }\n",
    "}\n",
    "\n",
    "cre_voi=c()\n",
    "cre_ari=c()\n",
    "cre_mean_voi=c()\n",
    "cre_mean_ari=c()\n",
    "for (nameval in names(sublist)) {\n",
    "  glifclust=read.csv(paste0(\"cluster_ids_\",pref,\"_\",nameval,\".csv\"),as.is=T)\n",
    "  glifclust=glifclust[match(rownames(featclust),glifclust[,1]),]\n",
    "  cre_voi=c(cre_voi,calc_cluster_diff(featclust[,1],glifclust[,2],1))\n",
    "  cre_ari=c(cre_ari,calc_cluster_diff(featclust[,1],glifclust[,2],2))\n",
    "  rand_voi=rand_cluster_diff(featclust[,1],glifclust[,2],1)\n",
    "  rand_ari=rand_cluster_diff(featclust[,1],glifclust[,2],2)\n",
    "  cre_mean_voi=c(cre_mean_voi,mean(rand_voi))\n",
    "  cre_mean_ari=c(cre_mean_ari,mean(rand_ari))\n",
    "}\n",
    "\n",
    "pdf(paste0(\"Fig_Supp17_comparison_to_Cre_lines_with_CIs_\",pref,\".pdf\"),useDingbats=F)\n",
    "par(mar = c(5,5,2,5))\n",
    "nameval=c(\"GLIF1\",\"GLIF2\",\"GLIF3\",\"GLIF4\",\"Featuresnospike\",\"Features\",\"GLIF1_spike_shape\",\"GLIF2_spike_shape\",\"GLIF3_spike_shape\",\"GLIF4_spike_shape\")\n",
    "U=c()\n",
    "L=c()\n",
    "M=c()\n",
    "for (mm in nameval) {\n",
    "  quants=quantile(cre_sub_voi[[mm]],probs=c(0.05,0.5,0.95))\n",
    "  U=c(U,quants[3])\n",
    "  L=c(L,quants[1])\n",
    "  M=c(M,quants[2])\n",
    "}\n",
    "mval=cre_mean_voi-cre_voi\n",
    "plotCI(1:length(mval),M,ui=U,li=L,col=\"black\",ylab=\"Adjusted VOI score\",xaxt='n',xlab='',main=\"Comparison to Cre lines\",ylim=c(0,max(c(U,L))))\n",
    "axis(side=1,at=1:length(cre_voi),labels=c(\"GLIF1\",\"GLIF2\",\"GLIF3\",\"GLIF4\",\"Features, no\\nspike-shape\",\"Features\",\"GLIF1+\\nSpike Shape\",\"GLIF2+\\nSpike Shape\",\"GLIF3+\\nSpike Shape\",\"GLIF4+\\nSpike Shape\"),las=2)\n",
    "par(new = T)\n",
    "U=c()\n",
    "L=c()\n",
    "M=c()\n",
    "for (mm in nameval) {\n",
    "  quants=quantile(cre_sub_ari[[mm]],probs=c(0.05,0.5,0.95))\n",
    "  U=c(U,quants[3])\n",
    "  L=c(L,quants[1])\n",
    "  M=c(M,quants[2])\n",
    "}\n",
    "mval=cre_ari-cre_mean_ari\n",
    "plotCI((1:length(mval))+0.1, M,ui=U,li=L,col=\"red\", axes=F, xlab=NA, ylab=NA,xlim=c(1,length(mval)),ylim=c(0,max(c(U,L))))\n",
    "axis(side=4,labels=F)\n",
    "at = axTicks(4)\n",
    "mtext(side = 4, text = at, at = at, col = \"red\", line = 1)\n",
    "mtext(side = 4, line = 3, 'Adjusted Rand Index',col='red')\n",
    "legend(\"topleft\",c(\"Adjusted VOI\",\"Adjusted Rand Index\"),fill=c(\"black\",\"red\"))\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8) Calculate Adjusted Rand and Adjusted Variation of Information Indices between GLIF clusterings and electrophysiological feature clustering, with confidence intervals based on bootstrapping\n",
    "#### This generates the right panel of Supplemental Figure 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>pdf:</strong> 2"
      ],
      "text/latex": [
       "\\textbf{pdf:} 2"
      ],
      "text/markdown": [
       "**pdf:** 2"
      ],
      "text/plain": [
       "pdf \n",
       "  2 "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pref=\"iterative_binary_clustering_2018\"\n",
    "sub_voi=list()\n",
    "sub_ari=list()\n",
    "load(paste0(\"bootstrappedclusters_\",pref,\".rda\"))\n",
    "featclust=read.csv(paste0(\"cluster_ids_\",pref,\"_Features.csv\"),as.is=T,row.names=1)\n",
    "namevals=c(\"GLIF1\",\"GLIF2\",\"GLIF3\",\"GLIF4\",\"Featuresnospike\",\"GLIF1_spike_shape\",\"GLIF2_spike_shape\",\"GLIF3_spike_shape\",\"GLIF4_spike_shape\")\n",
    "for (nameval in namevals) {\n",
    "  sub_voi[[nameval]]=c()\n",
    "  sub_ari[[nameval]]=c()\n",
    "  for (ii in 1:length(sublist[[nameval]])) {\n",
    "    checkclust=sublist[[nameval]][[ii]]\n",
    "    checkclust=checkclust[checkclust!=1]\n",
    "    keepclust=featclust[names(checkclust),1]\n",
    "    set.seed(ii)\n",
    "    rand_voi=rand_cluster_diff(keepclust,checkclust,1)\n",
    "    rand_ari=rand_cluster_diff(keepclust,checkclust,2)\n",
    "    sub_voi[[nameval]]=c(sub_voi[[nameval]],mean(rand_voi)-calc_cluster_diff(keepclust,checkclust,1))\n",
    "    sub_ari[[nameval]]=c(sub_ari[[nameval]],calc_cluster_diff(keepclust,checkclust,2)-mean(rand_ari))\n",
    "  }\n",
    "}\n",
    "all_voi=c()\n",
    "all_ari=c()\n",
    "mean_voi=c()\n",
    "mean_ari=c()\n",
    "for (nameval in namevals) {\n",
    "  glifclust=read.csv(paste0(\"cluster_ids_\",pref,\"_\",nameval,\".csv\"),as.is=T)\n",
    "  glifclust=glifclust[match(rownames(featclust),glifclust[,1]),]\n",
    "  all_voi=c(all_voi,calc_cluster_diff(featclust[,1],glifclust[,2],1))\n",
    "  all_ari=c(all_ari,calc_cluster_diff(featclust[,1],glifclust[,2],2))\n",
    "  rand_voi=rand_cluster_diff(featclust[,1],glifclust[,2],1)\n",
    "  rand_ari=rand_cluster_diff(featclust[,1],glifclust[,2],2)\n",
    "  mean_voi=c(mean_voi,mean(rand_voi))\n",
    "  mean_ari=c(mean_ari,mean(rand_ari))\n",
    "}\n",
    "pdf(paste0(\"Fig_Supp17_comparison_to_feature_clustering_with_CIs_\",pref,\".pdf\"),useDingbats=F)\n",
    "par(mar = c(5,5,2,5))\n",
    "U=c()\n",
    "L=c()\n",
    "M=c()\n",
    "for (mm in namevals) {\n",
    "  quants=quantile(sub_voi[[mm]],probs=c(0.05,0.5,0.95))\n",
    "  U=c(U,quants[3])\n",
    "  L=c(L,quants[1])\n",
    "  M=c(M,quants[2])\n",
    "}\n",
    "mval=mean_voi-all_voi\n",
    "plotCI(1:length(mval),M,ui=U,li=L,col=\"black\",ylab=\"Adjusted VOI score\",xaxt='n',xlab='',main=\"Comparison to clustering by features\",ylim=c(0,max(c(U,L))))\n",
    "axis(side=1,at=1:length(all_voi),labels=c(\"GLIF1\",\"GLIF2\",\"GLIF3\",\"GLIF4\",\"Features, no\\nspike-shape\",\"GLIF1+\\nSpike Shape\",\"GLIF2+\\nSpike Shape\",\"GLIF3+\\nSpike Shape\",\"GLIF4+\\nSpike Shape\"),las=2)\n",
    "par(new = T)\n",
    "U=c()\n",
    "L=c()\n",
    "M=c()\n",
    "for (mm in namevals) {\n",
    "  quants=quantile(sub_ari[[mm]],probs=c(0.05,0.5,0.95))\n",
    "  U=c(U,quants[3])\n",
    "  L=c(L,quants[1])\n",
    "  M=c(M,quants[2])\n",
    "}\n",
    "mval=all_ari-mean_ari\n",
    "plotCI((1:length(mval))+0.1, M,ui=U,li=L,col=\"red\", axes=F, xlab=NA, ylab=NA,xlim=c(1,length(mval)),ylim=c(0,max(c(U,L))))\n",
    "axis(side=4,labels=F)\n",
    "at = axTicks(4)\n",
    "mtext(side = 4, text = at, at = at, col = \"red\", line = 1)\n",
    "mtext(side = 4, line = 3, 'Adjusted Rand Index',col='red')\n",
    "legend(\"topleft\",c(\"Adjusted VOI\",\"Adjusted Rand Index\"),fill=c(\"black\",\"red\"))\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.1.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
